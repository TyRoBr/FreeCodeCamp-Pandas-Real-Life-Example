{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TyRoBr/FreeCodeCamp-Pandas-Real-Life-Example/blob/master/Fed_BioMed_practical_session_fl_algorithms_ai4health_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXERCICE 2: PLAY AROUND WITH FEDERATED LEARNING\n",
        "\n",
        "Now that you have understood the broad concept of federated learning from the previous tutorial, the goal of this tutorial is to introduce various specific federated learning algorithms and their associated parameters. Additionally, we will explore the limitations of these algorithms in the context of data heterogeneity."
      ],
      "metadata": {
        "id": "_guS9HAEa2oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Environment set-up"
      ],
      "metadata": {
        "id": "hibqxF9H0-qN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install some additional packages that are required by the tutorial but not included in Fed-BioMed"
      ],
      "metadata": {
        "id": "tkAlI15q1ZEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q tqdm colab-xterm \"jedi>=0.16\""
      ],
      "metadata": {
        "id": "JNxT3n8j2rSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 - Install Fed-BioMed\n",
        "First, download the wheel file."
      ],
      "metadata": {
        "id": "DlkTmuTxkcwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://docs.google.com/uc?export=download&id=1R8P5GcAsNQZDPy2ucmixkzd4huFpKvCR' -O fedbiomed-6.1.0-py3-none-any.whl"
      ],
      "metadata": {
        "id": "vsz4qUWjHgJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the wheel file. This will take some time.\n",
        "\n",
        "There might be some errors at the end, which can be safely ignored.\n",
        "\n",
        "If prompted, restart the session.\n"
      ],
      "metadata": {
        "id": "rVF9-VLrPASg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ./fedbiomed-6.1.0-py3-none-any.whl"
      ],
      "metadata": {
        "id": "75qo6A_qwuqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 - Import other packages\n",
        "\n",
        "Import other python packages useful for the rest of the tutorial."
      ],
      "metadata": {
        "id": "pn-3zufQh1Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xTjNMdWYh84v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 - Define useful functions"
      ],
      "metadata": {
        "id": "51Cuz-Nk5jb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_perf(exp, num_rounds):\n",
        "  nodes = exp.monitor()._metric_store.keys()\n",
        "\n",
        "  global_test_losses = {}\n",
        "  for node in nodes:\n",
        "    global_test_losses[node] = list()\n",
        "    for round in exp.monitor()._metric_store[node]['testing_global_updates']['ACCURACY'].keys():\n",
        "      round_loss = exp.monitor()._metric_store[node]['testing_global_updates']['ACCURACY'][round]['values']\n",
        "      global_test_losses[node].append(np.mean(round_loss))\n",
        "\n",
        "  train_losses = {}\n",
        "  for node in nodes:\n",
        "    train_losses[node] = list()\n",
        "    for round in exp.monitor()._metric_store[node]['training']['Loss'].keys():\n",
        "      round_loss = exp.monitor()._metric_store[node]['training']['Loss'][round]['values']\n",
        "      train_losses[node].append(np.mean(round_loss))\n",
        "\n",
        "  colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
        "\n",
        "  plt.figure()\n",
        "  for i,node in enumerate(nodes):\n",
        "    color = colors[i % len(colors)]\n",
        "    plt.plot(range(1,num_rounds+1), train_losses[node], '-', label=f'{node} training loss', color=color)\n",
        "  _ = plt.xlabel('Round')\n",
        "  _ = plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  for i,node in enumerate(nodes):\n",
        "    color = colors[i % len(colors)]\n",
        "    plt.plot(range(num_rounds+1), global_test_losses[node], '-', label=f'{node} global accuracy', color=color)\n",
        "  _ = plt.xlabel('Round')\n",
        "  _ = plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "qGsyROZo5oYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Tutorial use-case and federated learning set-up\n",
        "\n",
        "In this tutorial, we will use a set-up with 2 clients. We will first create the two components."
      ],
      "metadata": {
        "id": "uZm_x8zsJd8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Create node components\n",
        "\n"
      ],
      "metadata": {
        "id": "WeShw4YYgyod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "for i in {1..2}; do\n",
        "    fedbiomed component create -c node -p /content/fedbiomed_components/client_${i}\n",
        "done"
      ],
      "metadata": {
        "id": "qPLev76Pg6NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Download the data\n",
        "\n",
        "As a use-case, we will use the [MedNIST dataset](https://medmnist.com/). The MedNIST dataset is a standardized collection of medical images designed for benchmarking and training machine learning models. It includes various types of medical images such as X-rays, CT scans, and MRI images, categorized into different classes based on anatomical regions or imaging modalities. It serves as a medical equivalent to the MNIST dataset, facilitating research and development in medical image analysis.\n",
        "\n",
        "The goal of the tutorial is to create a model for modality classification.\n",
        "\n",
        "First, download the different datasets."
      ],
      "metadata": {
        "id": "hfL1aM1DJtJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install gdown\n",
        "mkdir -p /content/fedbiomed_components/notebooks/data\n",
        "cd /content/fedbiomed_components/notebooks/data\n",
        "gdown https://drive.google.com/uc?id=1SldskvQPiLwAmadgd2dBK_so4hYBYwCV -O /content/fedbiomed_components/notebooks/data/mednist_datasets.zip\n",
        "unzip /content/fedbiomed_components/notebooks/data/mednist_datasets.zip -d /content/fedbiomed_components/notebooks/data"
      ],
      "metadata": {
        "id": "XNzDKcdBhczN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 - Explore the datasets\n",
        "\n",
        "For each client, there are three datasets downloaded:\n",
        "- the 'no_skew' dataset, for which the number of images and the labels are honogeneous across the nodes,\n",
        "- the 'quantity_skew' dataset, for which the number of images is heterogeneous across the nodes,\n",
        "- the 'label_skew' dataset, for which the distribution of labels is heterogeneous across the nodes.\n",
        "\n",
        "Let's investigate a bit these differences."
      ],
      "metadata": {
        "id": "pDstNFU4MUOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Explore the no skew dataset\n"
      ],
      "metadata": {
        "id": "7qKrghdVrjAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory path\n",
        "base_dir = \"/content/fedbiomed_components/notebooks/data/mednist_datasets\"\n",
        "\n",
        "# Define clients\n",
        "clients = [\"client_1\", \"client_2\"]\n",
        "\n",
        "# Initialize a dictionary to store image counts\n",
        "data = {client: {} for client in clients}\n",
        "\n",
        "# Initialize a set to store unique modalities\n",
        "modalities = set()\n",
        "\n",
        "# Iterate over each client directory to collect modalities\n",
        "for client in clients:\n",
        "    client_path = os.path.join(base_dir, client, \"no_skew\", \"MedNIST\")\n",
        "    if os.path.exists(client_path):\n",
        "        # Retrieve modalities for the client\n",
        "        detected_modalities = [d for d in os.listdir(client_path) if os.path.isdir(os.path.join(client_path, d))]\n",
        "        modalities.update(detected_modalities)\n",
        "\n",
        "# Convert the set of modalities to a sorted list\n",
        "modalities = sorted(modalities)\n",
        "\n",
        "# Prepare data storage with dynamic modalities\n",
        "for client in clients:\n",
        "    for modality in modalities:\n",
        "        data[client][modality] = 0\n",
        "\n",
        "# Iterate over each client directory to count images\n",
        "for client in clients:\n",
        "    client_path = os.path.join(base_dir, client, \"no_skew\", \"MedNIST\")\n",
        "    if os.path.exists(client_path):\n",
        "        # Iterate over each modality folder\n",
        "        for modality in modalities:\n",
        "            modality_path = os.path.join(client_path, modality)\n",
        "            if os.path.exists(modality_path):\n",
        "                # Count the number of JPEG images in the modality folder\n",
        "                image_count = len([f for f in os.listdir(modality_path) if f.endswith('.jpeg')])\n",
        "                data[client][modality] = image_count\n",
        "\n",
        "# Plotting\n",
        "client_indices = np.arange(len(clients))\n",
        "bar_width = 0.1\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot bars for each modality\n",
        "for i, modality in enumerate(modalities):\n",
        "    counts = [data[client][modality] for client in clients]\n",
        "    ax.bar(client_indices + i * bar_width, counts, width=bar_width, label=modality)\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Client')\n",
        "ax.set_ylabel('Number of Images')\n",
        "ax.set_title('Distribution of Images by Client and Modality for no skew dataset')\n",
        "ax.set_xticks(client_indices + bar_width * (len(modalities) - 1) / 2)\n",
        "ax.set_xticklabels(clients)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UXU-DkWFrpnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at one example image for each modality:"
      ],
      "metadata": {
        "id": "Efva4cck6zAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory path for client 1\n",
        "base_dir = \"/content/fedbiomed_components/notebooks/data/mednist_datasets\"\n",
        "client = \"client_1\"\n",
        "client_path = os.path.join(base_dir, client, \"no_skew\", \"MedNIST\")\n",
        "\n",
        "# Check if the client path exists\n",
        "if os.path.exists(client_path):\n",
        "    # Retrieve modalities for client 1\n",
        "    modalities = sorted([d for d in os.listdir(client_path) if os.path.isdir(os.path.join(client_path, d))])\n",
        "\n",
        "    # Plot an example image from each modality\n",
        "    for modality in modalities:\n",
        "        modality_path = os.path.join(client_path, modality)\n",
        "        # List all JPEG images in the modality directory\n",
        "        image_files = [f for f in os.listdir(modality_path) if f.endswith('.jpeg')]\n",
        "\n",
        "        if image_files:\n",
        "            # Select the first image file\n",
        "            example_image_path = os.path.join(modality_path, image_files[0])\n",
        "            # Load and display the image\n",
        "            img = mpimg.imread(example_image_path)\n",
        "            plt.figure()\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.title(f\"Example Image from {client} - {modality}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "else:\n",
        "    print(f\"The specified path for {client} does not exist.\")"
      ],
      "metadata": {
        "id": "1SYOm17s64x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 Explore the quantity skew dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "dsOHDNM-4z_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory path\n",
        "base_dir = \"/content/fedbiomed_components/notebooks/data/mednist_datasets\"\n",
        "\n",
        "# Define clients\n",
        "clients = [\"client_1\", \"client_2\"]\n",
        "\n",
        "# Initialize a dictionary to store image counts\n",
        "data = {client: {} for client in clients}\n",
        "\n",
        "# Initialize a set to store unique modalities\n",
        "modalities = set()\n",
        "\n",
        "# Iterate over each client directory to collect modalities\n",
        "for client in clients:\n",
        "    client_path = os.path.join(base_dir, client, \"quantity_skew\", \"MedNIST\")\n",
        "    if os.path.exists(client_path):\n",
        "        # Retrieve modalities for the client\n",
        "        detected_modalities = [d for d in os.listdir(client_path) if os.path.isdir(os.path.join(client_path, d))]\n",
        "        modalities.update(detected_modalities)\n",
        "\n",
        "# Convert the set of modalities to a sorted list\n",
        "modalities = sorted(modalities)\n",
        "\n",
        "# Prepare data storage with dynamic modalities\n",
        "for client in clients:\n",
        "    for modality in modalities:\n",
        "        data[client][modality] = 0\n",
        "\n",
        "# Iterate over each client directory to count images\n",
        "for client in clients:\n",
        "    client_path = os.path.join(base_dir, client, \"quantity_skew\", \"MedNIST\")\n",
        "    if os.path.exists(client_path):\n",
        "        # Iterate over each modality folder\n",
        "        for modality in modalities:\n",
        "            modality_path = os.path.join(client_path, modality)\n",
        "            if os.path.exists(modality_path):\n",
        "                # Count the number of JPEG images in the modality folder\n",
        "                image_count = len([f for f in os.listdir(modality_path) if f.endswith('.jpeg')])\n",
        "                data[client][modality] = image_count\n",
        "\n",
        "# Plotting\n",
        "client_indices = np.arange(len(clients))\n",
        "bar_width = 0.1\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot bars for each modality\n",
        "for i, modality in enumerate(modalities):\n",
        "    counts = [data[client][modality] for client in clients]\n",
        "    ax.bar(client_indices + i * bar_width, counts, width=bar_width, label=modality)\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Client')\n",
        "ax.set_ylabel('Number of Images')\n",
        "ax.set_title('Distribution of Images by Client and Modality for quantity skew dataset')\n",
        "ax.set_xticks(client_indices + bar_width * (len(modalities) - 1) / 2)\n",
        "ax.set_xticklabels(clients)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cRd4isjK48kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can observe, the number of images in both clients is heterogenous, but the distribution of labels is homogeneous.\n",
        "\n"
      ],
      "metadata": {
        "id": "Im_sm5yt-Atk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3 - Explore the label skew dataset"
      ],
      "metadata": {
        "id": "QLloPQLr43j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the base directory path\n",
        "base_dir = \"/content/fedbiomed_components/notebooks/data/mednist_datasets\"\n",
        "\n",
        "# Define clients\n",
        "clients = [\"client_1\", \"client_2\"]\n",
        "\n",
        "# Initialize a dictionary to store image counts\n",
        "data = {client: {} for client in clients}\n",
        "\n",
        "# Initialize a set to store unique modalities\n",
        "modalities = set()\n",
        "\n",
        "# Iterate over each client directory to collect modalities\n",
        "for client in clients:\n",
        "    client_path = os.path.join(base_dir, client, \"label_skew\", \"MedNIST\")\n",
        "    if os.path.exists(client_path):\n",
        "        # Retrieve modalities for the client\n",
        "        detected_modalities = [d for d in os.listdir(client_path) if os.path.isdir(os.path.join(client_path, d))]\n",
        "        modalities.update(detected_modalities)\n",
        "\n",
        "# Convert the set of modalities to a sorted list\n",
        "modalities = sorted(modalities)\n",
        "\n",
        "# Prepare data storage with dynamic modalities\n",
        "for client in clients:\n",
        "    for modality in modalities:\n",
        "        data[client][modality] = 0\n",
        "\n",
        "# Iterate over each client directory to count images\n",
        "for client in clients:\n",
        "    client_path = os.path.join(base_dir, client, \"label_skew\", \"MedNIST\")\n",
        "    if os.path.exists(client_path):\n",
        "        # Iterate over each modality folder\n",
        "        for modality in modalities:\n",
        "            modality_path = os.path.join(client_path, modality)\n",
        "            if os.path.exists(modality_path):\n",
        "                # Count the number of JPEG images in the modality folder\n",
        "                image_count = len([f for f in os.listdir(modality_path) if f.endswith('.jpeg')])\n",
        "                data[client][modality] = image_count\n",
        "\n",
        "# Plotting\n",
        "client_indices = np.arange(len(clients))\n",
        "bar_width = 0.1\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot bars for each modality\n",
        "for i, modality in enumerate(modalities):\n",
        "    counts = [data[client][modality] for client in clients]\n",
        "    ax.bar(client_indices + i * bar_width, counts, width=bar_width, label=modality)\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Client')\n",
        "ax.set_ylabel('Number of Images')\n",
        "ax.set_title('Distribution of Images by Client and Modality for label skew dataset')\n",
        "ax.set_xticks(client_indices + bar_width * (len(modalities) - 1) / 2)\n",
        "ax.set_xticklabels(clients)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m3_8gcRz4Fqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can observe, the number of images in both clients is homogeneous, but the distribution of labels is heterogeneous."
      ],
      "metadata": {
        "id": "rxAJsG1b-mJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 - Integrate the data in Fed-BioMed nodes and start nodes\n",
        "\n",
        "For each client, create and add two fedbiomed dataset description files, each one corresponding to the two types of MedNIST datasets."
      ],
      "metadata": {
        "id": "6R1y_DPu_zcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "for i in {1..2}; do\n",
        "    for skew_type in no_skew quantity_skew label_skew; do\n",
        "        mkdir -p \"/content/fedbiomed_components/client_${i}/data/${skew_type}\"\n",
        "        cd \"/content/fedbiomed_components/client_${i}/data/${skew_type}\"\n",
        "        tee dataset.json << END\n",
        "{\n",
        "\"data_type\": \"mednist\",\n",
        "\"path\": \"/content/fedbiomed_components/notebooks/data/mednist_datasets/client_${i}/${skew_type}\",\n",
        "\"description\": \"MedNIST dataset with ${skew_type}\",\n",
        "\"name\": \"MedNIST ${skew_type} client ${i}\",\n",
        "\"tags\": \"mednist_${skew_type}\"\n",
        "}\n",
        "END\n",
        "    done\n",
        "done"
      ],
      "metadata": {
        "id": "-c4NcbqXhey3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the command line interface (CLI) to add a dataset to the Fed-BioMed database."
      ],
      "metadata": {
        "id": "uh33GRs31kds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "for i in {1..2}; do\n",
        "    for skew_type in no_skew quantity_skew label_skew; do\n",
        "        fedbiomed node --path /content/fedbiomed_components/client_${i} dataset add -f /content/fedbiomed_components/client_${i}/data/${skew_type}/dataset.json\n",
        "    done\n",
        "done"
      ],
      "metadata": {
        "id": "9HltuI8phlwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, le'ts start the fedbiomed nodes, as we already did in the previous tutorial."
      ],
      "metadata": {
        "id": "zApAj0vXuWoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First client:\n",
        "\n",
        "- Activate the Fed-BioMed software and leave it in standby, waiting to receive requests for training from the orchestrator.\n",
        "- Execute the cell below and wait for the terminal to appear.\n",
        "- Copy/paste the following line in the terminal, then hit `Enter`:\n",
        "\n",
        "```shell\n",
        "fedbiomed node --path /content/fedbiomed_components/client_1 start\n",
        "```"
      ],
      "metadata": {
        "id": "Z4yfF2fXoJUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "Qlkl9bEBoir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "6gDSz8LG-qXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the node starts, you should see the following message appear multiple times:\n",
        "\n",
        "```shell\n",
        "fedbiomed DEBUG - Researcher server is not available, will retry connect in 2 seconds\n",
        "```\n",
        "\n",
        "This is normal: the hospital is ready to work, but we have not given any workload yet."
      ],
      "metadata": {
        "id": "jOju98x2rUFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second client:\n",
        "\n",
        "- Activate the Fed-BioMed software and leave it in standby, waiting to receive requests for training from the orchestrator.\n",
        "- Execute the cell below and wait for the terminal to appear.\n",
        "- Copy/paste the following line in the terminal, then hit `Enter`:\n",
        "\n",
        "```shell\n",
        "fedbiomed node --path /content/fedbiomed_components/client_2 start\n",
        "```"
      ],
      "metadata": {
        "id": "P-GGvIUuCYJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "TXIgHqksCYJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the node starts, you should see the following message appear multiple times:\n",
        "\n",
        "```shell\n",
        "fedbiomed DEBUG - Researcher server is not available, will retry connect in 2 seconds\n",
        "```\n",
        "\n",
        "This is normal: the hospital is ready to work, but we have not given any workload yet."
      ],
      "metadata": {
        "id": "ZzSZnnNpCYJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - No skew datasets\n",
        "\n",
        "In this section of the tutorial, we will investigate the behaviour of a classical algorithm called Federated Averaging, depending on different parameters of the training.\n",
        "\n",
        "Federated Averaging (also known as [FedAvg](https://arxiv.org/pdf/1602.05629)) is a popular algorithm in federated learning. As most federated learning algorithm, it consists of two main phases: local node optimization and global averaging.\n",
        "\n",
        "### Initialization\n",
        "\n",
        "The process begins with initializing a global model with random weights or pre-trained weights. This global model is denoted as $w_0 $.\n",
        "\n",
        "### Local Node Optimization\n",
        "\n",
        "In each communication round $t$, a subset of clients $K$ is selected to participate in the training process. Each selected client $k$ performs the following steps:\n",
        "\n",
        "- **Download the Global Model**: Each client $k$ downloads the current global model weights $w_t$.\n",
        "\n",
        "- **Local Training**: Each client updates the model locally using its own dataset. This involves performing stochastic gradient descent (SGD) or any other optimization technique on the local data for a certain number of epochs or iterations. The local objective for client $k$ is to minimize the loss function $ F_k(w) $, defined as:\n",
        "\n",
        "  $$\n",
        "  F_k(w) = \\frac{1}{n_k} \\sum_{i=1}^{n_k} f_k(w; x_i, y_i)\n",
        "  $$\n",
        "\n",
        "  where $ n_k $ is the number of data samples on client $ k $, and $ f_k(w; x_i, y_i) $ is the loss function for the data sample $ (x_i, y_i) $.\n",
        "\n",
        "- **Compute Local Update**: After local training, each client computes the update to the global model. The updated local weights are denoted as $ w_{t+1}^k $.\n",
        "\n",
        "### Global Averaging\n",
        "\n",
        "After the local training phase, the updates from the participating clients are aggregated to update the global model:\n",
        "\n",
        "- **Upload Local Updates**: Each client $ k $ sends its local model weights $ w_{t+1}^k $ back to the central server.\n",
        "\n",
        "- **Aggregate Updates**: The central server aggregates these local updates to form a new global model. The global model update is typically a weighted average of the local models, where the weights are proportional to the number of data samples on each client. The global model update formula is:\n",
        "\n",
        "  $$\n",
        "  w_{t+1} = \\sum_{k=1}^{K} \\frac{n_k}{n} w_{t+1}^k\n",
        "  $$\n",
        "\n",
        "  where $ n $ is the total number of data samples across all clients, $ n_k $ is the number of data samples on client $ k $, and $ K $ is the number of participating clients.\n",
        "\n",
        "### Repeat\n",
        "\n",
        "The process of local training and global averaging is repeated for a predefined number of communication rounds or until convergence is achieved."
      ],
      "metadata": {
        "id": "jGgxM8PKufxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 - Experiment 1: FedAverage with small number of rounds and large number of local updates\n"
      ],
      "metadata": {
        "id": "0TYPYxueufxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 - Define a Training Plan\n",
        "\n",
        "As the goal of this tutorial is to use federated learning for a classification task of different image modalities in the MedNIST dataset, we will define a simple convolutional neural network using PyTorch. This model is defined in the training plan, as explained in the previous tutorial."
      ],
      "metadata": {
        "id": "SDeeuV8-ufxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
        "\n",
        "# Here we define the model to be used.\n",
        "\n",
        "class FedAvgTrainingPlan(TorchTrainingPlan):\n",
        "    class MyModel(torch.nn.Module):\n",
        "        \"\"\"definition of a PyTorch model, with its __init__ and forward methods\"\"\"\n",
        "        def __init__(self, model_args: dict):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "            self.fc1 = nn.Linear(16 * 16 * 16, model_args.get('num_classes', 6))\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.fc1(x)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def init_dependencies(self):\n",
        "        deps = [\"from torchvision import datasets, transforms\",\n",
        "                \"from torchvision.transforms import ToTensor\",\n",
        "                'from torch.optim import AdamW, SGD',\n",
        "                ]\n",
        "\n",
        "        return deps\n",
        "\n",
        "    def init_model(self, model_args: dict):\n",
        "        \"\"\"Defines your model here\"\"\"\n",
        "        return self.MyModel(model_args)\n",
        "\n",
        "    def init_optimizer(self, optimizer_args):\n",
        "        \"\"\"Defines your optimizer here\"\"\"\n",
        "        optimizer = AdamW(self.model().parameters(), lr=optimizer_args.get('lr', 0.001))\n",
        "        return optimizer\n",
        "\n",
        "    def training_data(self):\n",
        "        \"\"\"Defines data handling/parsing here\"\"\"\n",
        "        # Custom torch Dataloader for MedNIST data\n",
        "\n",
        "        preprocess = transforms.Compose([transforms.ToTensor()])\n",
        "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
        "\n",
        "        return DataManager(dataset=train_data, shuffle=True)\n",
        "\n",
        "    def training_step(self, data, target):\n",
        "        \"\"\"Defines cost function and how to compute loss\"\"\"\n",
        "        output = self.model().forward(data)\n",
        "        loss   = torch.nn.functional.nll_loss(output, target)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "7yZEt4-wufxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 - Define model parameters\n",
        "\n",
        "Here you can define `model_args`, a dictionary that contain parameters and hyperparameters for model definition. Here, we specify that the number of classes is 6."
      ],
      "metadata": {
        "id": "Cec-jhNJufxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = {\n",
        "    'num_classes': 6,\n",
        "}"
      ],
      "metadata": {
        "id": "aDX_4OXhufxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.3 - Define training arguments\n",
        "\n",
        "For the first experiment, we will use the FedAverage algorithm as discussed previously, with a large number of local updates. This parameter is defined in the training arguments.\n",
        "\n",
        "Define\n",
        "- batch size 8\n",
        "- learning rate 0.001\n",
        "- 50 local updates per round"
      ],
      "metadata": {
        "id": "UJo-4r5CufxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args1 = {\n",
        "    ??\n",
        "    'log_interval': 1,\n",
        "    'test_ratio' : 0.05,\n",
        "    'test_on_global_updates': True,\n",
        "}"
      ],
      "metadata": {
        "id": "CjPn3ZECufxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.4 - Create a FL experiment\n",
        "\n",
        "When creating the FL experiment, we provide the name of the desired aggregator algorithm: FedAverage, and the number of rounds (set it to 5).\n",
        "\n",
        "After initializing the experiment, check that both nodes have been selected for training."
      ],
      "metadata": {
        "id": "WxEOVUPzufxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fedbiomed.researcher.federated_workflows import Experiment\n",
        "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
        "\n",
        "tags = ??\n",
        "\n",
        "exp1 = Experiment(\n",
        "    ???\n",
        "                )"
      ],
      "metadata": {
        "id": "Zgf759W2ufxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.5 - Run the FL training experiment\n",
        "\n",
        "Launch the experiment."
      ],
      "metadata": {
        "id": "RLtzimbwufxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp1.run()"
      ],
      "metadata": {
        "id": "QtodbyKiufxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.6 - Plot the losses\n",
        "\n",
        "Plot the training losses and the accuracy metric. What do you observe ?"
      ],
      "metadata": {
        "id": "xfcA_nNnufxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp1, num_rounds_1)"
      ],
      "metadata": {
        "id": "vh62wxb07RYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.7 - Check FedAverage algorithm\n",
        "\n",
        "Check that the federated averaging weighted mean formula presented previously is indeed computed."
      ],
      "metadata": {
        "id": "wGvYl6H5ufxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_model = exp1.training_plan().model()"
      ],
      "metadata": {
        "id": "_JmhbAoNufxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies = exp1.training_replies()\n",
        "last_round_replies = replies[num_rounds_1-1]\n",
        "node_model_weights = list()\n",
        "sample_sizes = list()\n",
        "\n",
        "example_layer_name = 'conv1.weight'\n",
        "\n",
        "??"
      ],
      "metadata": {
        "id": "tCK03KHKufxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Experiment 2: FedAverage with large number of rounds and small number of local updates\n",
        "\n",
        "We will retart an experiment with Federated averaging algorithm, with a small number of local updates and a large number of global updates.\n",
        "\n",
        "Keep the same arguments as the previous experiment, but set\n",
        "- 5 local updates per round"
      ],
      "metadata": {
        "id": "M2Si3vuDuozV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 - Define training arguments"
      ],
      "metadata": {
        "id": "5bLW0LciuozV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "??"
      ],
      "metadata": {
        "id": "ob_VX9AsuozV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 - Create a FL experiment\n",
        "\n",
        "This time, set 50 rounds"
      ],
      "metadata": {
        "id": "K_rAa6dPuozV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp2 = ??"
      ],
      "metadata": {
        "id": "PgLUJwjKuozW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 - Run the FL training experiment"
      ],
      "metadata": {
        "id": "0Lp2s__DuozW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp2.run()"
      ],
      "metadata": {
        "id": "e3DqwUMauozW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 - Plot the losses"
      ],
      "metadata": {
        "id": "5Ffu_MCwuozW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp2, num_rounds_2)"
      ],
      "metadata": {
        "id": "juLdroii61bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a trade-off between communication cost and model convergence/stability.\n",
        "\n",
        "In case of homogeneous datasets:\n",
        "- More local updates (less communication) = faster local progress but risk of divergence.\n",
        "- More global updates (more communication) = slower local training but better global consistency.\n"
      ],
      "metadata": {
        "id": "ITq23FhquozX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Quantity skew datasets\n",
        "\n",
        "In federated learning, a \"quantity skew dataset\" refers to a scenario where the amount of data varies significantly across different clients or nodes. This means that some clients have a large volume of data, while others have much less. Such skew can impact the training process, as clients with more data may have a larger influence on the global model, potentially leading to biased or uneven model performance. Addressing quantity skew is important for ensuring that the federated learning model generalizes well across all clients.\n",
        "\n",
        "In this section of the tutorial, we will investigate the behaviour of several federated learning optimization algorithms with quantity skew datasets."
      ],
      "metadata": {
        "id": "nA5Jibg0OcMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 - Experiment 3: FedAverage"
      ],
      "metadata": {
        "id": "wC5cYvdiNfqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 - Define training arguments\n",
        "\n",
        "For the first experiment, we will use the FedAverage algorithm as discussed previously."
      ],
      "metadata": {
        "id": "kx0WecREO7qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args3 = {\n",
        "    'loader_args': { 'batch_size': 8, },\n",
        "    'optimizer_args': {\n",
        "        'lr': 1e-3\n",
        "    },\n",
        "    'num_updates': 25,\n",
        "    'dry_run': False,\n",
        "    'log_interval': 1,\n",
        "    'test_ratio' : 0.05,\n",
        "    'test_on_global_updates': True,\n",
        "}"
      ],
      "metadata": {
        "id": "YApSoDQJPBpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 - Create a FL experiment\n",
        "\n",
        "When creating the FL experiment, we provide the name of the desired aggregator algorithm: FedAverage.\n",
        "\n",
        "After initializing the experiment, check that both nodes have been selected for training."
      ],
      "metadata": {
        "id": "nQVf4Pvniep9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fedbiomed.researcher.federated_workflows import Experiment\n",
        "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
        "\n",
        "tags =  ['mednist_quantity_skew']\n",
        "num_rounds_3 = 50\n",
        "\n",
        "exp3 = Experiment(tags=tags,\n",
        "                 model_args=model_args,\n",
        "                 training_plan_class=FedAvgTrainingPlan,\n",
        "                 training_args=training_args3,\n",
        "                 round_limit=num_rounds_3,\n",
        "                 aggregator=FedAverage(),\n",
        "                 tensorboard=True\n",
        "                )"
      ],
      "metadata": {
        "id": "SYSNH6B4FkKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.5 - Run the FL training experiment\n",
        "\n",
        "Launch the experiment."
      ],
      "metadata": {
        "id": "p29-iA1Ojw8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp3.run()"
      ],
      "metadata": {
        "id": "_1ejK8laKPTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.6 - Plot the losses\n",
        "\n",
        "Plot the training losses and the accuracy metric. What do you observe ?"
      ],
      "metadata": {
        "id": "1VKGdjjLJmXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp3, num_rounds_3)"
      ],
      "metadata": {
        "id": "9DY0WI3X73HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we can observe problem of convergence for the node with less images, and uneven model performance, with lower performances for the node with less images.\n",
        "\n",
        "Due to the heterogeneity of data across clients, local updates drift away from the global model, leading to slower convergence and reduced performance."
      ],
      "metadata": {
        "id": "IdnGL5GyJ5LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 - Experiment 4: FedProx with large mu\n",
        "\n",
        "In the previous experiment, we saw the limitations of FedAverage algorithm in case of heterogeneous data, in terms of performance and convergence.\n",
        "\n",
        "Regularization techniques can help the convergence and the performances of training by smoothing the impact of global updates.\n",
        "\n",
        "In this experiment, we will use a federated learning algorithm with regularization, called [FedProx](https://arxiv.org/pdf/1812.06127).\n",
        "\n",
        "Federated Proximal (FedProx) is an advanced federated learning algorithm that builds upon Federated Averaging (FedAvg) by incorporating a proximal term. This term helps to stabilize training and improve convergence in heterogeneous settings.\n",
        "\n",
        "The initialization and global averaging steps are identical to FedAvg algorithm (see the explanation of FedAvg in previous experiments). Only the local node optimization part is modified as followed:\n",
        "\n",
        "### Local Node Optimization\n",
        "\n",
        "In each communication round $ t $, a subset of clients $ K $ is selected to participate in the training process. Each selected client $ k $ performs the following steps:\n",
        "\n",
        "- **Download the Global Model**: Each client $ k $ downloads the current global model weights $ w_t $.\n",
        "\n",
        "- **Local Training with Proximal Term**: Each client updates the model locally using its own dataset, but with an added proximal term to constrain the local updates. The local objective for client $ k $ is to minimize the following loss function $F_k(w) $:\n",
        "\n",
        "  $$\n",
        "  F_k(w) = \\frac{1}{n_k} \\sum_{i=1}^{n_k} f_k(w; x_i, y_i) + \\frac{\\mu}{2} \\| w - w_t\\|^2\n",
        "  $$\n",
        "\n",
        "  where:\n",
        "  - $ n_k $ is the number of data samples on client $ k $.\n",
        "  - $ f_k(w; x_i, y_i) $ is the loss function for the data sample $ (x_i, y_i) $.\n",
        "  - $ \\mu $ is a hyperparameter that controls the strength of the proximal term.\n",
        "  - $ \\|w - w_t\\|^2 $ is the squared Euclidean distance between the local model weights $ w $ and the global model weights $ w_t $.\n",
        "\n",
        "- **Compute Local Update**: After local training, each client computes the update to the global model. The updated local weights are denoted as $ w_{t+1}^k $.\n",
        "\n",
        "The proximal term $ \\frac{\\mu}{2} \\|w - w_t\\|^2 $ helps to prevent the local models from diverging too far from the global model, thus stabilizing the training process and improving convergence.\n",
        "\n",
        "- **Handling Data Heterogeneity**: FedProx is particularly effective in handling non-IID data across clients, as the proximal term helps to mitigate the impact of data heterogeneity.\n",
        "\n",
        "- **Hyperparameter $ \\mu $**: The hyperparameter $ \\mu $ controls the strength of the proximal term. A higher value of $ \\mu $ enforces the local models to stay closer to the global model, while a lower value allows more flexibility in local updates. Selecting an appropriate value for $ \\mu $ is crucial. Too high a value can restrict the local models too much, leading to slow convergence, while too low a value may not effectively mitigate client drift.\n",
        "\n",
        "### Activate FedProx in Fed-BioMed\n",
        "\n",
        "To enable Fedprox in Fed-BioMed, you need to set a value for the `fedprox_mu` key inside `training_args`."
      ],
      "metadata": {
        "id": "K3fjYnwJQcHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 - Define training arguments\n",
        "\n",
        "Perform an experiment with\n",
        "- 10 local updates per round\n",
        "- a value of 1 for the fedprox regularizer"
      ],
      "metadata": {
        "id": "wQ1lXFjlQcHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args4 = {\n",
        "    ??\n",
        "    'log_interval': 1,\n",
        "    'test_ratio' : 0.05,\n",
        "    'test_on_global_updates': True,\n",
        "}"
      ],
      "metadata": {
        "id": "717XAVdRQcHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 - Create a FL experiment\n",
        "\n",
        "run for 50 rounds"
      ],
      "metadata": {
        "id": "1ng96oGQQcHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp4 = ??"
      ],
      "metadata": {
        "id": "k16o0pgKQcHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.3 - Run the FL training experiment"
      ],
      "metadata": {
        "id": "d-HcQm5AQcHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp4.run()"
      ],
      "metadata": {
        "id": "lYIgMx_5QcHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.4 - Plot the losses"
      ],
      "metadata": {
        "id": "hMzHB6MPQcHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp4, num_rounds_4)"
      ],
      "metadata": {
        "id": "0HjTaYG88ptA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both clients exhibit a general downward trend in training loss over the rounds, indicating that the model is learning and improving.\n",
        "\n",
        "The local accuracy for both clients shows improvement over rounds.\n",
        "\n",
        "As you can see, the addition of the proximal term in FedProx helps stabilize the training process and improve convergence compared to FedAvg, especially in this heterogeneous settings. The fluctuations in loss and accuracy are typically less severe compared to FedAvg, as the proximal term helps to mitigate client drift by constraining local updates.\n",
        "\n",
        "However, the convergence of the model is quite slow, due to the quite high value of the mu parameter."
      ],
      "metadata": {
        "id": "xucn8dliQcHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 - Experiment 5: FedProx with small mu\n",
        "\n",
        "In this experiment, we will decrease the proximal parameter mu. What behaviour can you expect from a small mu ?"
      ],
      "metadata": {
        "id": "sSfj7Z6XR4or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1 - Define training arguments"
      ],
      "metadata": {
        "id": "dnm3tkQQR4os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args5 = {\n",
        "    ??\n",
        "    'log_interval': 1,\n",
        "    'test_ratio' : 0.05,\n",
        "    'test_on_global_updates': True,\n",
        "}"
      ],
      "metadata": {
        "id": "s1lX43LZR4ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2 - Create a FL experiment"
      ],
      "metadata": {
        "id": "-CGJWdDxR4ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp5 = ??"
      ],
      "metadata": {
        "id": "dkL7_RUGR4ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3 - Run the FL training experiment"
      ],
      "metadata": {
        "id": "9BP-gC65R4ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp5.run()"
      ],
      "metadata": {
        "id": "UclKcrarR4ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.4 - Plot the losses"
      ],
      "metadata": {
        "id": "b7ey4w57R4ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp5, num_rounds_5)"
      ],
      "metadata": {
        "id": "vIGr7T72AFbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can observe similar performances as FedAverage, with less convergence and worse accuracy for the node with less images."
      ],
      "metadata": {
        "id": "zP-GC3HnR4ov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Label skew datasets\n",
        "\n",
        "In federated learning, a \"label skew dataset\" refers to a scenario where the distribution of class labels varies significantly across different clients or nodes. This means that certain classes may be overrepresented in some clients' datasets while being underrepresented or completely absent in others. Label skew in federated learning can lead to biased models, convergence issues, and generalization challenges."
      ],
      "metadata": {
        "id": "UZyFQFqNVFOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 - Experiment 6: FedAverage\n",
        "\n",
        "We will try to solve the classification problem of MedNIST with FedAverage."
      ],
      "metadata": {
        "id": "Q0qfHtVbVFOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.1 - Define training arguments"
      ],
      "metadata": {
        "id": "j9hbcJHqVFOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args6 = {\n",
        "    'loader_args': { 'batch_size': 8, },\n",
        "    'optimizer_args': {\n",
        "        'lr': 1e-3\n",
        "    },\n",
        "    'num_updates': 10,\n",
        "    'dry_run': False,\n",
        "    'log_interval': 1,\n",
        "    'test_ratio' : 0.05,\n",
        "    'test_on_global_updates': True,\n",
        "}"
      ],
      "metadata": {
        "id": "gV-Ue7ttVFOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.2 - Create a FL experiment\n",
        "\n",
        "Don't forget to set the proper `tags` and choose a suitable [`aggregator`](https://fedbiomed.org/latest/tutorials/pytorch/04-Aggregation_in_Fed-BioMed/)."
      ],
      "metadata": {
        "id": "Jq7w6QyuVFOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fedbiomed.researcher.federated_workflows import Experiment\n",
        "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
        "\n",
        "tags =  ['mednist_label_skew']\n",
        "num_rounds_6 = 50\n",
        "\n",
        "exp6 = Experiment(tags=tags,\n",
        "                 model_args=model_args,\n",
        "                 training_plan_class=FedAvgTrainingPlan,\n",
        "                 training_args=training_args6,\n",
        "                 round_limit=num_rounds_6,\n",
        "                 aggregator=FedAverage(),\n",
        "                 tensorboard=True\n",
        "                )"
      ],
      "metadata": {
        "id": "6yvsTiGyVFOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.3 - Run the FL training experiment"
      ],
      "metadata": {
        "id": "wuF-_xtfVFOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp6.run()"
      ],
      "metadata": {
        "id": "-y2534qxVFOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.6 - Plot the losses"
      ],
      "metadata": {
        "id": "09NvATbBVFOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp6, num_rounds_6)"
      ],
      "metadata": {
        "id": "2n_HpiINBQig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe slow and 'chaotic' convergence. This is due to the fact that each node converges towards its local minimum, but the global minimum is not reached."
      ],
      "metadata": {
        "id": "Ik70omu_VFOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 - Experiment 7: Scaffold\n",
        "\n",
        "We will test another algorithm called [SCAFFOLD](https://arxiv.org/abs/1910.06378).\n",
        "\n",
        "SCAFFOLD (Stochastic Controlled Averaging for Federated Learning) is an advanced federated learning algorithm designed to improve convergence and performance in the presence of data heterogeneity. It introduces correction terms to mitigate the \"client-drift\" issue that arises due to the variance in local updates.\n",
        "\n",
        "For the details of the algorithm, check the [original paper](https://arxiv.org/abs/1910.06378).\n",
        "\n"
      ],
      "metadata": {
        "id": "qoI3372yX0MM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.1 - Define a Training Plan\n",
        "\n",
        "For using [SCAFFOLD in Fedbiomed](https://fedbiomed.org/latest/user-guide/researcher/aggregation/#scaffold), we need to change the training plan, because as explained previously, this algorithm has optimization part on the researcher side, and on the nodes sides.\n",
        "\n",
        "Moreover, for using this advanced optimizer, Fedbiomed relies on a library called [Declearn](https://fedbiomed.org/latest/user-guide/advanced-optimization/).\n"
      ],
      "metadata": {
        "id": "6hcGO_DRYU71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
        "\n",
        "class ScaffoldTrainingPlan(TorchTrainingPlan):\n",
        "    class MyModel(torch.nn.Module):\n",
        "        \"\"\"definition of a PyTorch model, with its __init__ and forward methods\"\"\"\n",
        "        def __init__(self, model_args: dict):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "            self.fc1 = nn.Linear(16 * 16 * 16, model_args.get('num_classes', 6))\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.fc1(x)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def init_dependencies(self):\n",
        "        deps = [\"from torchvision import datasets, transforms\",\n",
        "                \"from torchvision.transforms import ToTensor\",\n",
        "                \"from fedbiomed.common.optimizers.optimizer import Optimizer\",\n",
        "                \"from fedbiomed.common.optimizers.declearn import ScaffoldClientModule\"\n",
        "                ]\n",
        "\n",
        "        return deps\n",
        "\n",
        "    def init_model(self, model_args: dict):\n",
        "        \"\"\"Defines your model here\"\"\"\n",
        "        return self.MyModel(model_args)\n",
        "\n",
        "    def init_optimizer(self, optimizer_args):\n",
        "        \"\"\"Defines your optimizer here\"\"\"\n",
        "        return Optimizer(lr=optimizer_args[\"lr\"],\n",
        "                         modules=[ScaffoldClientModule()])\n",
        "\n",
        "    def training_data(self):\n",
        "        \"\"\"Defines data handling/parsing here\"\"\"\n",
        "        # Custom torch Dataloader for MedNIST data\n",
        "\n",
        "        preprocess = transforms.Compose([transforms.ToTensor()])\n",
        "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
        "\n",
        "        return DataManager(dataset=train_data, shuffle=True)\n",
        "\n",
        "    def training_step(self, data, target):\n",
        "        \"\"\"Defines cost function and how to compute loss\"\"\"\n",
        "        output = self.model().forward(data)\n",
        "        loss   = torch.nn.functional.nll_loss(output, target)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "kb4h0yFzYU72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.2 - Define model parameters\n",
        "\n",
        "Here you can define `model_args`, a dictionary that contain parameters and hyperparameters for model definition."
      ],
      "metadata": {
        "id": "d45ZOswLYU72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = {\n",
        "    'num_classes': 6,\n",
        "}"
      ],
      "metadata": {
        "id": "5w5RAsZkYU72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.3 - Define training arguments"
      ],
      "metadata": {
        "id": "R86hvQUvYU73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args7 = {\n",
        "    'loader_args': { 'batch_size': 8, },\n",
        "    'optimizer_args': {\n",
        "        'lr': 1e-3\n",
        "    },\n",
        "    'num_updates': 10,\n",
        "    'dry_run': False,\n",
        "    'log_interval': 1,\n",
        "    'test_ratio' : 0.05,\n",
        "    'test_on_global_updates': True,\n",
        "}"
      ],
      "metadata": {
        "id": "gMCyEEZtYU73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.4 - Create a FL experiment\n",
        "\n",
        "Don't forget to set the proper `tags` and choose a suitable [`aggregator`](https://fedbiomed.org/latest/tutorials/pytorch/04-Aggregation_in_Fed-BioMed/)."
      ],
      "metadata": {
        "id": "r9Ic1BBhYU73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags =  ['mednist_label_skew']\n",
        "num_rounds_7 = 50\n",
        "\n",
        "exp7 = Experiment(tags=tags,\n",
        "                 model_args=model_args,\n",
        "                 training_plan_class=ScaffoldTrainingPlan,\n",
        "                 training_args=training_args7,\n",
        "                 round_limit=num_rounds_7,\n",
        "                 aggregator=FedAverage(),\n",
        "                 tensorboard=True\n",
        "                )"
      ],
      "metadata": {
        "id": "3YqlNN7cYU73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.5 - Define the server optimizer for SCAFFOLD"
      ],
      "metadata": {
        "id": "8JiJOxFtY7rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fedbiomed.common.optimizers import Optimizer\n",
        "from fedbiomed.common.optimizers.declearn import ScaffoldServerModule\n",
        "\n",
        "scaffold_opt = Optimizer(lr=.8, modules=[ScaffoldServerModule()])\n",
        "exp7.set_agg_optimizer(scaffold_opt)"
      ],
      "metadata": {
        "id": "yK6dkerjZDm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.6 - Run the FL training experiment"
      ],
      "metadata": {
        "id": "aY8RVfbGYU74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp7.run()"
      ],
      "metadata": {
        "id": "wLG7MexCYU74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.7 - Plot the losses"
      ],
      "metadata": {
        "id": "09EsLzxPYU74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perf(exp7, num_rounds_7)"
      ],
      "metadata": {
        "id": "igwm9kiAECE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convergence of SCAFFOLD is slower, but can be more homogeneous."
      ],
      "metadata": {
        "id": "nVecYKIZYU75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Optional exercices\n",
        "\n",
        "- Look for the other [optimizers](https://fedbiomed.org/latest/user-guide/advanced-optimization/) available in Fedbiomed\n",
        "- Play around with [batches](https://fedbiomed.org/latest/user-guide/researcher/experiment/#sub-arguments-for-optimizer-and-differential-privacy) instead of num_updates\n",
        "- Try to find an optimal mu in fedprox (for several mu, try to optimize both time of convergence and loss)\n",
        "- Investigate how you can implement a [custom aggregator](https://fedbiomed.org/latest/user-guide/researcher/aggregation/) in fedbiomed\n"
      ],
      "metadata": {
        "id": "ffZ8dAW4aGpz"
      }
    }
  ]
}